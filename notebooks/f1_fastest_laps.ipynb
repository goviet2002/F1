{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45cd8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\")))\n",
    "from utils.path import get_project_root\n",
    "from utils.f1_shared import ssl_context, head, base_url, years, test_function\n",
    "\n",
    "PROJECT_ROOT = get_project_root()\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"f1_fastest_laps\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "CHECKPOINTS_DIR = os.path.join(PROJECT_ROOT, \"data\", \"f1_checkpoints\")\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b5256b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_fastest_laps(session, year):\n",
    "    \"\"\"Scrape fastest lap data for a specific year\"\"\"\n",
    "    url = f\"{base_url}/en/results/{year}/fastest-laps\"\n",
    "    \n",
    "    async with session.get(url, headers=head) as response:\n",
    "        if response.status != 200:\n",
    "            print(f\"Failed to load {url}. Status: {response.status}\")\n",
    "            return None\n",
    "\n",
    "        html = await response.text()\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        \n",
    "        # Find table\n",
    "        table = soup.find('table', class_='f1-table-with-data')\n",
    "        \n",
    "        if not table:\n",
    "            print(f\"No fastest lap data found for {year}\")\n",
    "            return None\n",
    "            \n",
    "        # Get headers\n",
    "        headers = [header.text.strip() for header in table.find('thead').find_all('th')]\n",
    "        \n",
    "        # Get rows\n",
    "        rows = table.find('tbody').find_all('tr')\n",
    "        data = []\n",
    "        \n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            row_data = []\n",
    "            \n",
    "            # Extract Grand Prix name\n",
    "            grand_prix = cols[0].text.strip()\n",
    "            row_data.append(grand_prix)\n",
    "            \n",
    "            # Extract Driver name (handle responsive design spans)\n",
    "            driver_cell = cols[1]\n",
    "            first_name_span = driver_cell.select_one('span.max-desktop\\\\:hidden')\n",
    "            last_name_span = driver_cell.select_one('span.max-tablet\\\\:hidden')\n",
    "            \n",
    "            if first_name_span and last_name_span:\n",
    "                first_name = first_name_span.text.strip()\n",
    "                last_name = last_name_span.text.strip()\n",
    "                driver_name = f\"{first_name} {last_name}\"\n",
    "            else:\n",
    "                # For older pages without responsive spans\n",
    "                driver_name = driver_cell.text.strip()\n",
    "                \n",
    "            row_data.append(driver_name)\n",
    "            \n",
    "            # Extract Car/Team name\n",
    "            car = cols[2].text.strip()\n",
    "            row_data.append(car)\n",
    "            \n",
    "            # Extract Time\n",
    "            time = cols[3].text.strip()\n",
    "            row_data.append(time)\n",
    "                \n",
    "            data.append(row_data)\n",
    "        \n",
    "        # Create output structure\n",
    "        output = {\n",
    "            \"headers\": headers,\n",
    "            \"data\": data\n",
    "        }\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7873551",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def collect_fastest_laps_data(start_year=years[0], end_year=years[-1]):\n",
    "    \"\"\"Collect fastest lap data for a range of years into a single file with year column\"\"\"\n",
    "    connector = aiohttp.TCPConnector(ssl=ssl_context)\n",
    "    timeout = aiohttp.ClientTimeout(total=60)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Collection to store combined data\n",
    "    all_headers = None\n",
    "    combined_data = []\n",
    "    all_data_by_year = {}  # For checkpoints\n",
    "\n",
    "    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:\n",
    "        for i, year in enumerate(range(start_year, end_year + 1)):\n",
    "            print(f\"Fetching fastest lap data for {year}...\")\n",
    "            year_data = await scrape_fastest_laps(session, year)\n",
    "            \n",
    "            if year_data:\n",
    "                # Set headers if not already set\n",
    "                if all_headers is None:\n",
    "                    # Add \"Year\" to the headers list\n",
    "                    all_headers = year_data[\"headers\"] + [\"Year\"]\n",
    "                \n",
    "                # Add year column to each row and add to combined data\n",
    "                for row in year_data[\"data\"]:\n",
    "                    # Add year to each row\n",
    "                    row_with_year = row + [str(year)]\n",
    "                    combined_data.append(row_with_year)\n",
    "                \n",
    "                # Store in year-indexed structure for checkpoint\n",
    "                all_data_by_year[str(year)] = {\n",
    "                    \"headers\": year_data[\"headers\"],\n",
    "                    \"data\": year_data[\"data\"]\n",
    "                }\n",
    "                \n",
    "                print(f\"Added {len(year_data['data'])} entries from {year}\")\n",
    "                \n",
    "                # Save checkpoint at intervals\n",
    "                checkpoint_file = os.path.join(CHECKPOINTS_DIR, \"fastest_laps_latest.json\")\n",
    "                if (i + 1) % 5 == 0 or i == end_year - start_year:\n",
    "                    with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(all_data_by_year, f, indent=2, ensure_ascii=False)\n",
    "                    \n",
    "                    # Also save the current combined data\n",
    "                    combined_file_path = os.path.join(DATA_DIR, \"all_fastest_laps.json\")\n",
    "                    with open(combined_file_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump({\n",
    "                            \"headers\": all_headers,\n",
    "                            \"data\": combined_data\n",
    "                        }, f, indent=2, ensure_ascii=False)\n",
    "                    \n",
    "                    print(f\"Saved checkpoint and combined data after processing {year}\")\n",
    "            else:\n",
    "                print(f\"No data available for {year}\")\n",
    "        \n",
    "        # Final save of the combined data\n",
    "        combined_file_path = os.path.join(DATA_DIR, \"fastest_laps.json\")\n",
    "        with open(combined_file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                \"headers\": all_headers,\n",
    "                \"data\": combined_data\n",
    "            }, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        print(f\"\\nCompleted fastest laps data collection in {total_time:.2f} seconds\")\n",
    "        print(f\"Total entries collected: {len(combined_data)}\")\n",
    "        print(f\"All data saved to: {combined_file_path}\")\n",
    "        \n",
    "        # Delete checkpoint file after successful completion\n",
    "        checkpoint_file = os.path.join(CHECKPOINTS_DIR, \"fastest_laps_latest.json\")\n",
    "        if os.path.exists(checkpoint_file):\n",
    "            os.remove(checkpoint_file)\n",
    "            print(f\"Deleted checkpoint file: {checkpoint_file}\")\n",
    "        \n",
    "        return {\n",
    "            \"headers\": all_headers,\n",
    "            \"data\": combined_data\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "264d9256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching fastest lap data for 1950...\n",
      "Added 7 entries from 1950\n",
      "Fetching fastest lap data for 1951...\n",
      "Added 8 entries from 1951\n",
      "Fetching fastest lap data for 1952...\n",
      "Added 8 entries from 1952\n",
      "Fetching fastest lap data for 1953...\n",
      "Added 9 entries from 1953\n",
      "Fetching fastest lap data for 1954...\n",
      "Added 9 entries from 1954\n",
      "Saved checkpoint and combined data after processing 1954\n",
      "Fetching fastest lap data for 1955...\n",
      "Added 7 entries from 1955\n",
      "Fetching fastest lap data for 1956...\n",
      "Added 8 entries from 1956\n",
      "Fetching fastest lap data for 1957...\n",
      "Added 8 entries from 1957\n",
      "Fetching fastest lap data for 1958...\n",
      "Added 11 entries from 1958\n",
      "Fetching fastest lap data for 1959...\n",
      "Added 9 entries from 1959\n",
      "Saved checkpoint and combined data after processing 1959\n",
      "Fetching fastest lap data for 1960...\n",
      "Added 10 entries from 1960\n",
      "Fetching fastest lap data for 1961...\n",
      "Added 8 entries from 1961\n",
      "Fetching fastest lap data for 1962...\n",
      "Added 9 entries from 1962\n",
      "Fetching fastest lap data for 1963...\n",
      "Added 10 entries from 1963\n",
      "Fetching fastest lap data for 1964...\n",
      "Added 10 entries from 1964\n",
      "Saved checkpoint and combined data after processing 1964\n",
      "Fetching fastest lap data for 1965...\n",
      "Added 10 entries from 1965\n",
      "Fetching fastest lap data for 1966...\n",
      "Added 9 entries from 1966\n",
      "Fetching fastest lap data for 1967...\n",
      "Added 11 entries from 1967\n",
      "Fetching fastest lap data for 1968...\n",
      "Added 12 entries from 1968\n",
      "Fetching fastest lap data for 1969...\n",
      "Added 11 entries from 1969\n",
      "Saved checkpoint and combined data after processing 1969\n",
      "Fetching fastest lap data for 1970...\n",
      "Added 13 entries from 1970\n",
      "Fetching fastest lap data for 1971...\n",
      "Added 11 entries from 1971\n",
      "Fetching fastest lap data for 1972...\n",
      "Added 12 entries from 1972\n",
      "Fetching fastest lap data for 1973...\n",
      "Added 15 entries from 1973\n",
      "Fetching fastest lap data for 1974...\n",
      "Added 15 entries from 1974\n",
      "Saved checkpoint and combined data after processing 1974\n",
      "Fetching fastest lap data for 1975...\n",
      "Added 14 entries from 1975\n",
      "Fetching fastest lap data for 1976...\n",
      "Added 16 entries from 1976\n",
      "Fetching fastest lap data for 1977...\n",
      "Added 17 entries from 1977\n",
      "Fetching fastest lap data for 1978...\n",
      "Added 16 entries from 1978\n",
      "Fetching fastest lap data for 1979...\n",
      "Added 15 entries from 1979\n",
      "Saved checkpoint and combined data after processing 1979\n",
      "Fetching fastest lap data for 1980...\n",
      "Added 14 entries from 1980\n",
      "Fetching fastest lap data for 1981...\n",
      "Added 15 entries from 1981\n",
      "Fetching fastest lap data for 1982...\n",
      "Added 16 entries from 1982\n",
      "Fetching fastest lap data for 1983...\n",
      "Added 15 entries from 1983\n",
      "Fetching fastest lap data for 1984...\n",
      "Added 16 entries from 1984\n",
      "Saved checkpoint and combined data after processing 1984\n",
      "Fetching fastest lap data for 1985...\n",
      "Added 16 entries from 1985\n",
      "Fetching fastest lap data for 1986...\n",
      "Added 16 entries from 1986\n",
      "Fetching fastest lap data for 1987...\n",
      "Added 16 entries from 1987\n",
      "Fetching fastest lap data for 1988...\n",
      "Added 16 entries from 1988\n",
      "Fetching fastest lap data for 1989...\n",
      "Added 16 entries from 1989\n",
      "Saved checkpoint and combined data after processing 1989\n",
      "Fetching fastest lap data for 1990...\n",
      "Added 16 entries from 1990\n",
      "Fetching fastest lap data for 1991...\n",
      "Added 16 entries from 1991\n",
      "Fetching fastest lap data for 1992...\n",
      "Added 16 entries from 1992\n",
      "Fetching fastest lap data for 1993...\n",
      "Added 16 entries from 1993\n",
      "Fetching fastest lap data for 1994...\n",
      "Added 18 entries from 1994\n",
      "Saved checkpoint and combined data after processing 1994\n",
      "Fetching fastest lap data for 1995...\n",
      "Added 17 entries from 1995\n",
      "Fetching fastest lap data for 1996...\n",
      "Added 16 entries from 1996\n",
      "Fetching fastest lap data for 1997...\n",
      "Added 17 entries from 1997\n",
      "Fetching fastest lap data for 1998...\n",
      "Added 16 entries from 1998\n",
      "Fetching fastest lap data for 1999...\n",
      "Added 16 entries from 1999\n",
      "Saved checkpoint and combined data after processing 1999\n",
      "Fetching fastest lap data for 2000...\n",
      "Added 17 entries from 2000\n",
      "Fetching fastest lap data for 2001...\n",
      "Added 17 entries from 2001\n",
      "Fetching fastest lap data for 2002...\n",
      "Added 17 entries from 2002\n",
      "Fetching fastest lap data for 2003...\n",
      "Added 16 entries from 2003\n",
      "Fetching fastest lap data for 2004...\n",
      "Added 18 entries from 2004\n",
      "Saved checkpoint and combined data after processing 2004\n",
      "Fetching fastest lap data for 2005...\n",
      "Added 19 entries from 2005\n",
      "Fetching fastest lap data for 2006...\n",
      "Added 18 entries from 2006\n",
      "Fetching fastest lap data for 2007...\n",
      "Added 17 entries from 2007\n",
      "Fetching fastest lap data for 2008...\n",
      "Added 18 entries from 2008\n",
      "Fetching fastest lap data for 2009...\n",
      "Added 17 entries from 2009\n",
      "Saved checkpoint and combined data after processing 2009\n",
      "Fetching fastest lap data for 2010...\n",
      "Added 19 entries from 2010\n",
      "Fetching fastest lap data for 2011...\n",
      "Added 19 entries from 2011\n",
      "Fetching fastest lap data for 2012...\n",
      "Added 20 entries from 2012\n",
      "Fetching fastest lap data for 2013...\n",
      "Added 19 entries from 2013\n",
      "Fetching fastest lap data for 2014...\n",
      "Added 19 entries from 2014\n",
      "Saved checkpoint and combined data after processing 2014\n",
      "Fetching fastest lap data for 2015...\n",
      "Added 19 entries from 2015\n",
      "Fetching fastest lap data for 2016...\n",
      "Added 21 entries from 2016\n",
      "Fetching fastest lap data for 2017...\n",
      "Added 20 entries from 2017\n",
      "Fetching fastest lap data for 2018...\n",
      "Added 21 entries from 2018\n",
      "Fetching fastest lap data for 2019...\n",
      "Added 21 entries from 2019\n",
      "Saved checkpoint and combined data after processing 2019\n",
      "Fetching fastest lap data for 2020...\n",
      "Added 17 entries from 2020\n",
      "Fetching fastest lap data for 2021...\n",
      "Added 21 entries from 2021\n",
      "Fetching fastest lap data for 2022...\n",
      "Added 22 entries from 2022\n",
      "Fetching fastest lap data for 2023...\n",
      "Added 20 entries from 2023\n",
      "Fetching fastest lap data for 2024...\n",
      "Added 24 entries from 2024\n",
      "Saved checkpoint and combined data after processing 2024\n",
      "Fetching fastest lap data for 2025...\n",
      "Added 9 entries from 2025\n",
      "Saved checkpoint and combined data after processing 2025\n",
      "\n",
      "Completed fastest laps data collection in 14.40 seconds\n",
      "Total entries collected: 1133\n",
      "All data saved to: c:\\Users\\anhvi\\OneDrive\\Desktop\\F1 Projekt\\data\\f1_fastest_laps\\all_fastest_laps.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Collect fastest lap data\n",
    "    await collect_fastest_laps_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
