{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd8003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\")))\n",
    "from utils.path import get_project_root\n",
    "from utils.f1_shared import ssl_context, head, base_url, years, test_function\n",
    "\n",
    "PROJECT_ROOT = get_project_root()\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"f1_fastest_laps\")\n",
    "CHECKPOINTS_DIR = os.path.join(PROJECT_ROOT, \"data\", \"f1_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5256b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_fastest_laps(session, year):\n",
    "    \"\"\"Scrape fastest lap data for a specific year\"\"\"\n",
    "    url = f\"{base_url}/en/results/{year}/fastest-laps\"\n",
    "    \n",
    "    async with session.get(url, headers=head) as response:\n",
    "        if response.status != 200:\n",
    "            print(f\"Failed to load {url}. Status: {response.status}\")\n",
    "            return None\n",
    "\n",
    "        html = await response.text()\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        \n",
    "        # Find table\n",
    "        table = soup.find('table', class_='f1-table-with-data')\n",
    "        \n",
    "        if not table:\n",
    "            print(f\"No fastest lap data found for {year}\")\n",
    "            return None\n",
    "            \n",
    "        # Get headers\n",
    "        headers = [header.text.strip() for header in table.find('thead').find_all('th')]\n",
    "        \n",
    "        # Get rows\n",
    "        rows = table.find('tbody').find_all('tr')\n",
    "        data = []\n",
    "        \n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            row_data = []\n",
    "            \n",
    "            # Extract Grand Prix name\n",
    "            grand_prix = cols[0].text.strip()\n",
    "            row_data.append(grand_prix)\n",
    "            \n",
    "            # Extract Driver name (handle responsive design spans)\n",
    "            driver_cell = cols[1]\n",
    "            first_name_span = driver_cell.select_one('span.max-desktop\\\\:hidden')\n",
    "            last_name_span = driver_cell.select_one('span.max-tablet\\\\:hidden')\n",
    "            \n",
    "            if first_name_span and last_name_span:\n",
    "                first_name = first_name_span.text.strip()\n",
    "                last_name = last_name_span.text.strip()\n",
    "                driver_name = f\"{first_name} {last_name}\"\n",
    "            else:\n",
    "                # For older pages without responsive spans\n",
    "                driver_name = driver_cell.text.strip()\n",
    "                \n",
    "            row_data.append(driver_name)\n",
    "            \n",
    "            # Extract Car/Team name\n",
    "            car = cols[2].text.strip()\n",
    "            row_data.append(car)\n",
    "            \n",
    "            # Extract Time\n",
    "            time = cols[3].text.strip()\n",
    "            row_data.append(time)\n",
    "                \n",
    "            data.append(row_data)\n",
    "        \n",
    "        # Create output structure\n",
    "        output = {\n",
    "            \"headers\": headers,\n",
    "            \"data\": data\n",
    "        }\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7873551",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def collect_fastest_laps_data(start_year=years[0], end_year=years[-1]):\n",
    "    \"\"\"Collect fastest lap data for a range of years\"\"\"\n",
    "    connector = aiohttp.TCPConnector(ssl=ssl_context)\n",
    "    timeout = aiohttp.ClientTimeout(total=60)\n",
    "    start_time = time.time()\n",
    "\n",
    "    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:\n",
    "        # Create directories\n",
    "        fastest_laps_dir = os.path.join(DATA_DIR, \"fastest_laps\")\n",
    "        os.makedirs(fastest_laps_dir, exist_ok=True)\n",
    "        \n",
    "        for year in range(start_year, end_year + 1):\n",
    "            print(f\"Fetching fastest lap data for {year}...\")\n",
    "            data = await scrape_fastest_laps(session, year)\n",
    "            \n",
    "            if data:\n",
    "                end_time = time.time()\n",
    "                total_time = end_time - start_time\n",
    "                print(f\"\\nCompleted fastest laps data collection in {total_time:.2f} seconds:\")\n",
    "\n",
    "                # Save to JSON file\n",
    "                file_path = os.path.join(fastest_laps_dir, f\"{year}_fastest_lap.json\")\n",
    "                \n",
    "                with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "                    \n",
    "                print(f\"Saved fastest lap data for {year} with {len(data['data'])} entries\")\n",
    "            else:\n",
    "                print(f\"No data available for {year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Collect fastest lap data\n",
    "    await collect_fastest_laps_data()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
