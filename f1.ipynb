{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "55dbb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import certifi\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "head = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
    "base_url = \"https://www.formula1.com\"\n",
    "\n",
    "# Get years that statistics have been published\n",
    "current_year = datetime.now().year\n",
    "years = [year for year in range(1950, current_year + 1)]\n",
    "\n",
    "# Helper function to save data to CSV\n",
    "def save_to_csv(data, headers, filename):\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a886d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_races_year(year):\n",
    "    # Default values in case elements are not found\n",
    "    race_date = None\n",
    "    circuit = None\n",
    "    city = None\n",
    "    \n",
    "    # URL of the page\n",
    "    url = f\"{base_url}/en/results/{year}/races\"\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url, headers=head, verify=certifi.where())\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find table\n",
    "        table = soup.find('table', class_='f1-table-with-data')\n",
    "        \n",
    "        if table:\n",
    "            headers = [header.text.strip() for header in table.find('thead').find_all('th')]\n",
    "            \n",
    "            rows = table.find('tbody').find_all('tr')\n",
    "            data = []\n",
    "            race_links = []\n",
    "            \n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                row_data = []\n",
    "                \n",
    "                for i, col in enumerate(cols):\n",
    "                    if i == 2: #Driver column\n",
    "                        winner = col.text.strip().replace(\"\\xa0\", \" \")[:-3]\n",
    "                        row_data.append(winner)\n",
    "                    else:\n",
    "                        row_data.append(col.text.strip())\n",
    "                        \n",
    "                # Append the row data to the data list (only once per row)\n",
    "                data.append(row_data)\n",
    "                \n",
    "                # Extract race link\n",
    "                race_link = cols[0].find('a')['href']\n",
    "                full_link = f\"{base_url}/en/results/{year}/{race_link}\"\n",
    "                race_links.append((row_data[0], full_link))\n",
    "                \n",
    "    return data, headers, race_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d9c7b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_race_location(race_url):\n",
    "    response = requests.get(race_url, headers=head, verify=certifi.where())\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the location table\n",
    "        header_section = soup.find('div', class_='max-tablet:flex-col flex gap-xs')\n",
    "        \n",
    "        if header_section:\n",
    "            location_info = header_section.find_all('p')\n",
    "            \n",
    "            race_date = location_info[0].text.strip()[:-5]\n",
    "            track = location_info[1].text.strip().split(\", \")\n",
    "            circuit = track[0]\n",
    "            city = track[1]\n",
    "            \n",
    "    return race_date, circuit, city\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_race = []\n",
    "races = []\n",
    "\n",
    "headers_race_location = ['Grand Prix', 'Circuit', 'Country/City', 'Year', 'Date']\n",
    "race_location = []\n",
    "\n",
    "# Step 1: First collect all race links\n",
    "all_race_links = []\n",
    "for year in years:\n",
    "    race, header_race, race_links = scrape_races_year(year)\n",
    "    races.extend(race)\n",
    "    \n",
    "    all_race_links.extend([(link[0], link[1]) for link in race_links])\n",
    "\n",
    "    if len(headers_race) == 0:\n",
    "        headers_race = header_race\n",
    "        \n",
    "# Process race links in parallel to get location data\n",
    "def process_race_link(race_link_tuple):\n",
    "    grand_prix, url = race_link_tuple\n",
    "    try:\n",
    "        race_date, circuit, city = scrape_race_location(url)\n",
    "        return [grand_prix, circuit, city, year, race_date]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")\n",
    "        return None\n",
    "    \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "    results = executor.map(process_race_link, all_race_links)\n",
    "        \n",
    "race_location = [r for r in results if r is not None]\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel requests\n",
    "save_to_csv(races, headers_race, \"races\")\n",
    "save_to_csv(race_location, headers_race_location, \"race_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afded3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('13 May', 'Silverstone Circuit', 'Great Britain')\n"
     ]
    }
   ],
   "source": [
    "print(scrape_race_location(\"https://www.formula1.com/en/results/1950/races/94/great-britain/race-result\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
